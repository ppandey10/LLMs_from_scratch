{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json \n",
    "import tiktoken\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset json file\n",
    "with open(\"/home/ge73qip/LLMs/LLMs_from_scratch/instruction-data.json\", \"r\") as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Evaluate the following phrase by transforming it into the spelling given.',\n",
       "  'input': 'freind --> friend',\n",
       "  'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'},\n",
       " {'instruction': 'Edit the following sentence for grammar.',\n",
       "  'input': 'He go to the park every day.',\n",
       "  'output': 'He goes to the park every day.'},\n",
       " {'instruction': 'Convert 45 kilometers to meters.',\n",
       "  'input': '',\n",
       "  'output': '45 kilometers is 45000 meters.'},\n",
       " {'instruction': \"Rewrite this sentence to start with 'Although': Despite the rain, they went for a walk.\",\n",
       "  'input': '',\n",
       "  'output': 'Although it was raining, they went for a walk.'},\n",
       " {'instruction': 'What are the first 10 square numbers?',\n",
       "  'input': '',\n",
       "  'output': '1, 4, 9, 16, 25, 36, 49, 64, 81, 100.'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is extracted/downloaded, we move to structuring the data in the most common format called Apalca.\n",
    "Example:\n",
    "Input:\n",
    "```json\n",
    "{\n",
    "    \"instruction\": \"Change the following sentence to past perfect tense.\",\n",
    "    \"input\": \"They finish the game.\",\n",
    "    \"output\": \"They had finished the game.\"\n",
    "}\n",
    "```\n",
    "\n",
    "Converted:\n",
    "```\n",
    "Below is an instruction that describes a task. Write a response that satisfies the instruction.\n",
    "\n",
    "### Instruction\n",
    "Change the following sentence to past perfect tense.\n",
    "\n",
    "### Input\n",
    "They finish the game.\n",
    "\n",
    "### Response\n",
    "They had finished the game.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing the conversion\n",
    "# we've to perform tokenisation \n",
    "# here, i will incorporate all the modification in the same function\n",
    "def format_input_entry(entry):\n",
    "    instruction = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write an appropriate response for it.\"\n",
    "        f\"\\n\\n### Instruction: \\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input = (\n",
    "        f\"\\n\\n### Input: \\n\"\n",
    "        f\"{entry['input']}\" if entry['input'] else \"\"\n",
    "    )\n",
    "    \n",
    "    combined = instruction + input\n",
    "\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write an appropriate response for it.\n",
      "\n",
      "### Instruction: \n",
      "Rewrite this sentence to start with 'Although': Despite the rain, they went for a walk.\n"
     ]
    }
   ],
   "source": [
    "# testing the conversion\n",
    "print(format_input_entry(dataset[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train, val and test\n",
    "def split_dataset(dataset, train_ratio=0.85, val_ratio=0.1, test_ratio=0.05):\n",
    "    train_portion = int(len(dataset) * train_ratio)\n",
    "    val_portion = int(len(dataset) * val_ratio)\n",
    "    test_portion = int(len(dataset) * test_ratio)\n",
    "    return dataset[:train_portion], dataset[train_portion:train_portion + val_portion], dataset[train_portion + val_portion:train_portion + val_portion + test_portion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935 110 55\n"
     ]
    }
   ],
   "source": [
    "# split the data\n",
    "train_data, val_data, test_data = split_dataset(dataset)\n",
    "print(len(train_data), len(val_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pytorch dataset\n",
    "class nakliInstructionFineTuneDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer):\n",
    "        self.dataset = dataset\n",
    "        self.encoded_dataset = []\n",
    "        \n",
    "        for item in self.dataset:\n",
    "            input_modified = format_input_entry(item)\n",
    "            response_modified = f\"\\n\\nResponse: \\n{item['output']}\"\n",
    "            apalca_type_format = input_modified + response_modified\n",
    "            self.encoded_dataset.append(tokenizer.encode(apalca_type_format))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encoded_dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dataset ---\n",
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 281, 5035, 2882, 329, 340, 13, 198, 198, 21017, 46486, 25, 220, 198, 36, 2100, 4985, 262, 1708, 9546, 416, 25449, 340, 656, 262, 24993, 1813, 13, 198, 198, 21017, 23412, 25, 220, 198, 19503, 521, 14610, 1545, 198, 198, 31077, 25, 220, 198, 464, 24993, 286, 262, 1813, 9546, 366, 19503, 521, 1, 318, 11491, 11, 262, 3376, 24993, 318, 366, 6726, 1911]\n"
     ]
    }
   ],
   "source": [
    "# test the nakliInstructionFineTuneDataset\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "train_pytorch_dataset = nakliInstructionFineTuneDataset(\n",
    "    dataset=train_data,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(\"\\n--- Dataset ---\")\n",
    "print(train_pytorch_dataset.encoded_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "# varying length/tokens for each sample\n",
    "print(len(train_pytorch_dataset.encoded_dataset[0]))\n",
    "print(len(train_pytorch_dataset.encoded_dataset[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we move to important aspect:\n",
    "# padding -> target generation -> replace padding with -100 in target\n",
    "# all this is performed for a single batch\n",
    "\n",
    "def collate_fn_with_padding(batch, padding_token_id=50256, device=\"cpu\"):\n",
    "    # since, each sample has different length, we need to pad them\n",
    "    # find max length\n",
    "    max_length = max(len(sample)+1 for sample in batch)\n",
    "\n",
    "    # padded batch \n",
    "    padded_inputs = []\n",
    "    for sample in batch:\n",
    "        # add padding token to make all samples same length\n",
    "        padded_sample = sample + [padding_token_id] * (max_length - len(sample))\n",
    "\n",
    "        # remove extra padding token from targets\n",
    "        padded_inputs.append(torch.tensor(padded_sample[:-1]))\n",
    "\n",
    "    # convert to tensor\n",
    "    padded_inputs = torch.stack(padded_inputs).to(device)\n",
    "\n",
    "    return padded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,     2, 50256, 50256, 50256],\n",
      "        [    3,     4,     5,     6,     7],\n",
      "        [    8,     9,    10, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "input_1 = [1, 2]\n",
    "input_2 = [3, 4, 5, 6, 7]\n",
    "input_3 = [8, 9, 10]\n",
    "\n",
    "batch_1 = [input_1, input_2, input_3]\n",
    "\n",
    "padded_batch_1 = collate_fn_with_padding(batch_1)\n",
    "print(padded_batch_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i will add padding + target\n",
    "def collate_fn_with_padNtarget(batch, padding_token_id=50256, device=\"cpu\"):\n",
    "    # since, each sample has different length, we need to pad them\n",
    "    # find max length\n",
    "    max_length = max(len(sample)+1 for sample in batch)\n",
    "\n",
    "    # padded batch \n",
    "    padded_inputs = []\n",
    "    padded_targets = []\n",
    "\n",
    "    for sample in batch:\n",
    "        # add padding token to make all samples same length\n",
    "        padded_sample = sample + [padding_token_id] * (max_length - len(sample))\n",
    "\n",
    "        # remove extra padding token from targets\n",
    "        padded_inputs.append(torch.tensor(padded_sample[:-1]))\n",
    "        padded_targets.append(torch.tensor(padded_sample[1:])) # shift by 1\n",
    "\n",
    "    # convert to tensor\n",
    "    padded_inputs = torch.stack(padded_inputs).to(device)\n",
    "    padded_targets = torch.stack(padded_targets).to(device)\n",
    "\n",
    "    return padded_inputs, padded_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,     2, 50256, 50256, 50256],\n",
      "        [    3,     4,     5,     6,     7],\n",
      "        [    8,     9,    10, 50256, 50256]])\n",
      "tensor([[    2, 50256, 50256, 50256, 50256],\n",
      "        [    4,     5,     6,     7, 50256],\n",
      "        [    9,    10, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "# test use case\n",
    "# testing\n",
    "input_1 = [1, 2]\n",
    "input_2 = [3, 4, 5, 6, 7]\n",
    "input_3 = [8, 9, 10]\n",
    "\n",
    "batch_1 = [input_1, input_2, input_3]\n",
    "\n",
    "padded_input_1, padded_target_1 = collate_fn_with_padNtarget(batch_1)\n",
    "print(padded_input_1)\n",
    "print(padded_target_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False,  True,  True,  True])\n",
      "tensor([2, 3, 4])\n",
      "tensor([    9,    10, 50256,  -100,  -100])\n"
     ]
    }
   ],
   "source": [
    "mask = padded_target_1[2] == 50256\n",
    "indices = torch.nonzero(mask).squeeze()\n",
    "if indices.numel() > 1:\n",
    "    padded_target_1[2][indices[1:]] = -100\n",
    "\n",
    "print(mask)\n",
    "print(indices)\n",
    "print(padded_target_1[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final version of collate function\n",
    "# converts all tokens with 50256 id to -100,\n",
    "# so that they are not considered during cross entropy loss calculation\n",
    "\n",
    "# i will add padding + target + replace with -100\n",
    "def collate_func(batch, padding_token_id=50256, allowed_max_length=None, device=\"cpu\"):\n",
    "    # since, each sample has different length, we need to pad them\n",
    "    # find max length\n",
    "    max_length = max(len(sample)+1 for sample in batch)\n",
    "\n",
    "    # padded batch \n",
    "    padded_inputs = []\n",
    "    padded_targets = []\n",
    "\n",
    "    for sample in batch:\n",
    "        # add padding token to make all samples same length\n",
    "        padded_sample = sample + [padding_token_id] * (max_length - len(sample))\n",
    "\n",
    "        padded_inpt = torch.tensor(padded_sample[:-1])\n",
    "        padded_targ = torch.tensor(padded_sample[1:])\n",
    "\n",
    "        # replace output padding token with -100\n",
    "        mask = padded_targ == padding_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            padded_targ[indices[1:]] = -100\n",
    "\n",
    "        if allowed_max_length is not None:\n",
    "            padded_inpt = padded_inpt[:allowed_max_length]\n",
    "            padded_targ = padded_targ[:allowed_max_length]\n",
    "\n",
    "        padded_inputs.append(padded_inpt)\n",
    "        padded_targets.append(padded_targ)\n",
    "\n",
    "    # convert to tensor\n",
    "    padded_inputs = torch.stack(padded_inputs).to(device)\n",
    "    padded_targets = torch.stack(padded_targets).to(device)\n",
    "\n",
    "    return padded_inputs, padded_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,     2, 50256, 50256, 50256],\n",
      "        [    3,     4,     5,     6,     7],\n",
      "        [    8,     9,    10, 50256, 50256]])\n",
      "tensor([[    2, 50256,  -100,  -100,  -100],\n",
      "        [    4,     5,     6,     7, 50256],\n",
      "        [    9,    10, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = collate_func(batch_1)\n",
    "\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = nakliInstructionFineTuneDataset(\n",
    "    dataset=train_data,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_func,\n",
    "    drop_last=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_dataset = nakliInstructionFineTuneDataset(\n",
    "    dataset=val_data,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_func,\n",
    "    drop_last=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 86]) torch.Size([8, 86])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "for input, target in train_dataloader:\n",
    "    print(input.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          281,  5035,  2882,   329,   340,    13,   198,   198, 21017, 46486,\n",
      "           25,   220,   198,  2061,   318,   262,  6697,   286,   705, 22031,\n",
      "        30960,   198,   198, 31077,    25,   220,   198,   464,  6697,   286,\n",
      "          705, 22031,     6,   318,   705,  2395,   499,  4458, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256])\n",
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   281,\n",
      "         5035,  2882,   329,   340,    13,   198,   198, 21017, 46486,    25,\n",
      "          220,   198,  2061,   318,   262,  6697,   286,   705, 22031, 30960,\n",
      "          198,   198, 31077,    25,   220,   198,   464,  6697,   286,   705,\n",
      "        22031,     6,   318,   705,  2395,   499,  4458, 50256,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n"
     ]
    }
   ],
   "source": [
    "print(input[0])\n",
    "print(target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 13:18:09.905766: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745320690.425999 2425090 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745320690.582660 2425090 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745320691.828843 2425090 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745320691.828939 2425090 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745320691.828948 2425090 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745320691.828954 2425090 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-22 13:18:11.955640: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 50257, 'embd_dim': 768, 'context_length': 256, 'dropout': 0.1, 'num_heads': 12, 'num_blocks': 12, 'qkv_bias': False}\n"
     ]
    }
   ],
   "source": [
    "# loading GPT model\n",
    "from nakliGPT import nakliGPT\n",
    "from trainer import load_config\n",
    "\n",
    "# load config\n",
    "base_config = load_config(\"/home/ge73qip/LLMs/LLMs_from_scratch/nakliGPT/configuration/configuration.yaml\")\n",
    "\n",
    "print(base_config[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"embd_dim\": 768, \"context_length\": 1024, \"num_blocks\": 12, \"num_heads\": 12, \"qkv_bias\": True},\n",
    "    \"gpt2-medium (355M)\": {\"embd_dim\": 1024, \"context_length\": 1024, \"num_blocks\": 24, \"num_heads\": 16, \"qkv_bias\": True},\n",
    "    \"gpt2-large (774M)\": {\"embd_dim\": 1280, \"context_length\": 1024, \"num_blocks\": 36, \"num_heads\": 20, \"qkv_bias\": True},\n",
    "    \"gpt2-xl (1558M)\": {\"embd_dim\": 1600, \"context_length\": 1024, \"num_blocks\": 48, \"num_heads\": 25, \"qkv_bias\": True},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "base_config[\"model\"].update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'embd_dim': 1024,\n",
       " 'context_length': 1024,\n",
       " 'dropout': 0.1,\n",
       " 'num_heads': 16,\n",
       " 'num_blocks': 24,\n",
       " 'qkv_bias': True}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_config[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nakliGPT(\n",
       "  (token_embedding): Embedding(50257, 1024)\n",
       "  (positional_embedding): Embedding(1024, 1024)\n",
       "  (dropout_embedding): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_block): nakliTransformerDecoder(\n",
       "    (attention): nakliMultiHeadAttention(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (feed_forward): nakliFeedForward(\n",
       "      (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (n_transformer_blocks): Sequential(\n",
       "    (0): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (12): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (13): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (14): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (15): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (16): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (17): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (18): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (19): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (20): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (21): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (22): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (23): nakliTransformerDecoder(\n",
       "      (attention): nakliMultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_output): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): nakliFeedForward(\n",
       "        (W): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (W_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (W_output): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from load_pretrained import load_weights_into_gpt\n",
    "\n",
    "model = nakliGPT(base_config)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write an appropriate response for it.\n",
      "\n",
      "### Instruction: \n",
      "What type of cloud is typically associated with thunderstorms?\n"
     ]
    }
   ],
   "source": [
    "# testing the loaded model\n",
    "input_text = format_input_entry(val_data[1])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_utils import nakliGreedySampling\n",
    "\n",
    "new_token_ids_generator = nakliGreedySampling(\n",
    "    model, \n",
    "    tokenizer, \n",
    "    num_new_tokens=35, \n",
    "    max_context_length=base_config[\"model\"][\"context_length\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = new_token_ids_generator.generate_text(\n",
    "    torch.tensor(tokenizer.encode(input_text)).unsqueeze(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write an appropriate response for it.\n",
      "\n",
      "### Instruction: \n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "A: A thunderstorm is a storm that is associated with lightning.\n",
      "\n",
      "### Instruction: \n",
      "\n",
      "What is the difference between a thunderstorm and a tornado\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: A thunderstorm is a storm that is associated with lightning.\n",
      "\n",
      "### Instruction: \n",
      "\n",
      "What is the difference between a thunderstorm and a tornado\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:  43%|     | 50/116 [05:10<06:48,  6.19s/it, loss=1.1] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Step 50: Loss = 1.1032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:  54%|    | 63/116 [06:32<05:32,  6.27s/it, loss=0.174] "
     ]
    }
   ],
   "source": [
    "# fine tune the weights based on the dataset\n",
    "from trainer import nakliTrainer\n",
    "# load trainer\n",
    "trainer = nakliTrainer(\n",
    "    config=base_config,\n",
    "    model=model,\n",
    "    dataloader=train_dataloader\n",
    ")\n",
    "\n",
    "# train\n",
    "trainer.train()\n",
    "\n",
    "# save model\n",
    "model_path = \"nakliGPT_model_fine_tuned.pth\"\n",
    "trainer.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
