# Large Language Models from Scratch
Building large language models from the ground up â€” a step-by-step guide to understanding and implementing transformer-based architectures without relying on high-level libraries

I will implement all the important papers in the field of large language models.

**Implemented Models**

1. `nakliGPT`: A replica of OpenAI's GPT-2 with causal attention (DONE!)
2. `nakliGPT_flash`: A replica of OpenAI's GPT-2 with causal attention and flash attention
3. `nakliGPT_sparse`: A replica of OpenAI's GPT-3 with causal attention and sparse attention
