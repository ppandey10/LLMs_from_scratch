# LLMs_from_scratch
Building large language models from the ground up â€” a step-by-step guide to understanding and implementing transformer-based architectures without relying on high-level libraries

1. nakliGPT: A replica of OpenAI's GPT-2 with causal attention (DONE!)
2. nakliGPT_flash: A replica of OpenAI's GPT-2 with causal attention and flash attention
3. nakliGPT_sparse: A replica of OpenAI's GPT-3 with causal attention and sparse attention
